# The neural representation of visually evoked emotion is high-dimensional, categorical, and distributed across transmodal brain regions

This repository contains the data and code for replicating results in our paper: [Horikawa, Cowen, Keltner, and Kamitani (2019) The neural representation of emotion is high-dimensional, categorical, and distributed across transmodal brain regions. bioRxiv](https://www.biorxiv.org/content/10.1101/872192v1.abstract).
We investigated the neural representation of visually evoked emotions using fMRI responses to 2185 emotionally evocative short videos generated by Alan S. Cowen and Dacher Keltner (PNAS, 2017).


## Data (fMRI data and features)

- The preprocessed fMRI data for five subjects and ratings/features (category, dimension, visual object, and semantic) will be available at <http://figshare>.
- The fMRI data will be saved as the [BrainDecoderToolbox2](https://github.com/KamitaniLab/BrainDecoderToolbox2) format.
- The unpreprocessed fMRI data will be available at [OpenNeuro](https://openneuro.org/datasets/ds002425).

## Video stimuli

- We used 2185 emotion evocative short videos collected by Cowen and Keltner (2017).   
- You can request the videos with emotion ratings from the following URL (https://goo.gl/forms/XErJw9sBeyuOyp5Q2).


## Code
Matlab and Python scripts for replicating main results of our study are available from [code/](code/).

This code include
  - Data preparations for delineating indivual ROIs, including WholeBrain, HCP360 ROIs, subcortical regions
  - (regularized) linear regression analyses (encoding/decoding) between MRI data 
     and labels (category, dimension, vision, semantic) assosiated with 2196 (2181 unique) emotion evocative movie clips.
  - Representational similarity analysis
  - K-means clustering using emotion-related brain activity (encoding results are necessary)

Preparations:
  - Set preprocessed fmri data in root/data/fmri/SubjectX/preprocessed/ 
  - Set roiInf.mat file in root/code/data/fmri/misc/
  - Set feature data in root/data/features/ 
  - Set principal gradient data in root/data/fmri/SubjectX/pringrad/ 
  - Set BrainDecodeeerToolbox2 in root/code/libraries/ 

Main parts:
  - To go through all analyses and get all result figures, run this and python scripts as below.
    0. run this script with setting 1 for roiDataPreparation variable (multiple cpu can work in parallel)
    1. run this script with setting 1 for performDecAnalyses/performEncAnalyses/performRSAnalyses variables (multiple cpu can work in parallel)
    2. run this script with setting 1 for summaryDecAnalyses/summaryEncAnalyses/summaryRSAnalyses variables
    3. run this script with setting 1 for performeAdditionalAnalysis variable
    4. run python scripts to perform UMAP analyses.
    5. run this script with setting 1 for showDecResults/showEncResults/showRSAResults variable

Note:
  - Decoding, encoding, and representational similarity analyses can be performed independently.
  - Two umap analysis implemented in python scripts requires results of decoding and encoding analyses.
  - The analysis part (2) will take about 1 day using 100 cpu to complete all the computations.


